---
title: "Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ Llama 3 êµ¬í˜„ ë° ì‹¤í–‰ ë°©ë²•"
description: ""
coverImage: "/assets/img/2024-07-10-ImplementingandRunningLlama3withHuggingFacesTransformersLibrary_0.png"
date: 2024-07-10 00:25
ogImage:
  url: /assets/img/2024-07-10-ImplementingandRunningLlama3withHuggingFacesTransformersLibrary_0.png
tag: Tech
originalTitle: "Implementing and Running Llama 3 with Hugging Faceâ€™s Transformers Library"
link: "https://medium.com/@manuelescobar-dev/implementing-and-running-llama-3-with-hugging-faces-transformers-library-40e9754d8c80"
isUpdated: true
---

## Llama 3ì„ Hugging Face Transformersì™€ í•¨ê»˜ ì‹¤í–‰í•˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œ

![img](/assets/img/2024-07-10-ImplementingandRunningLlama3withHuggingFacesTransformersLibrary_0.png)

LLM ë°°í¬ ì‹œë¦¬ì¦ˆì˜ ì¼í™˜ìœ¼ë¡œ, ì´ ê¸°ì‚¬ëŠ” Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Llama 3ë¥¼ êµ¬í˜„í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ê°€ì¥ ë„ë¦¬ í™œìš©ë˜ë©° ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ Llama 3ì˜ ì§€ì—­ êµ¬í˜„ì— ëŒ€í•œ ì ‘ê·¼ì„±ê³¼ ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥ì„±ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.

íŠœí† ë¦¬ì–¼ì€ Llama-3-8B-Instructë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ Hugging Faceì—ì„œ ì„ íƒí•œ ëª¨ë¸ì—ë„ ë™ì¼í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤. Llama-3-8B-InstructëŠ” ìš”ì•½ ë° ì§ˆë¬¸ ì‘ë‹µê³¼ ê°™ì€ ì—¬ëŸ¬ ì‘ì—…ì—ì„œ ì„¸ë°€ ì¡°ì •ëœ 80ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ ëª¨ë¸ì— í•´ë‹¹í•©ë‹ˆë‹¤. ëŒ€ì•ˆìœ¼ë¡œ, sequence-to-sequence ìƒì„±ì— êµìœ¡ëœ ë² ì´ìŠ¤ ëª¨ë¸ì¸ Llama-3-8Bë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

## í•˜ë“œì›¨ì–´ ìš”êµ¬ ì‚¬í•­

ì´ íŠœí† ë¦¬ì–¼ì„ ì •í™•í•˜ê²Œ ë”°ë¼ê°€ë ¤ë©´ ì ì–´ë„ 8GBì˜ GPU ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë©”ì„œë“œì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì¶”ê°€ ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ìë£Œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”:

- LLM í›ˆë ¨ ë° ì¶”ë¡ ì— ëŒ€í•œ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­
- LLM ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­ ê³„ì‚°ê¸°

# Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°œìš”

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìˆ˜ì²œ ê°œì˜ ë¯¸ë¦¬ í›ˆë ¨ëœ ëª¨ë¸ì„ í¬í•¨í•œ ê°•ë ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸, ë¹„ì „ ë° ì˜¤ë””ì˜¤ ì˜ì—­ì—ì„œ ì‘ì—…ì„ ìˆ˜í–‰í•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë¶„ë¥˜, ì§ˆì˜ ì‘ë‹µ, ìš”ì•½, ë²ˆì—­ ë˜ëŠ” 100ì—¬ê°œ ì´ìƒì˜ ì–¸ì–´ë¡œ í…ìŠ¤íŠ¸ ìƒì„±ì´ í•„ìš”í•œ ê²½ìš°, íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ëª¨ë“  ê²ƒì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ ë¶„ë¥˜, ê°ì²´ íƒì§€ ë° ì„¸ë¶„í™”ì™€ ê°™ì€ ì´ë¯¸ì§€ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•˜ë©°, ìŒì„± ì¸ì‹ ë° ìŒì„± ë¶„ë¥˜ì™€ ê°™ì€ ì˜¤ë””ì˜¤ ì‘ì—…ì—ë„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ê²Œë‹¤ê°€ í…Œì´ë¸” ì§ˆì˜ ì‘ë‹µ, OCR, ë¹„ë””ì˜¤ ë¶„ë¥˜ ë“±ê³¼ ê°™ì€ ë³µí•© ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ë‘í•  ì´ìœ 

- ì‰¬ìš´ ì‚¬ìš©: ë¯¸ë¦¬ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë‹¤ëª©ì : í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë° ë‹¤ì¤‘ ëª¨ë‹¬ ì‘ì—…ì„ ì§€ì›í•©ë‹ˆë‹¤.
- ë§¤ë„ëŸ¬ìš´ í†µí•©: Jax, PyTorch ë° TensorFlowì™€ í•¨ê»˜ ì‘ë™í•˜ì—¬ í”„ë ˆì„ì›Œí¬ ê°„ì— ì‰½ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë†’ì€ ì„±ëŠ¥: ë‚®ì€ ì§„ì… ì¥ë²½ê³¼ í•¨ê»˜ ë‹¤ì–‘í•œ ì‘ì—…ì— ëŒ€í•œ ìµœì‹  ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤.
- ë¹„ìš© íš¨ìœ¨ì : ê³µìœ  ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° ë¹„ìš©ì„ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê³ ë ¤í•´ë³¼ ì‚¬í•­

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

- ëª¨ë“ˆí™”ë˜ì§€ ì•ŠìŒ: ì²˜ìŒë¶€í„° ì‹ ê²½ë§ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
- íŠ¹ì • í›ˆë ¨ API: í•´ë‹¹ ëª¨ë¸ì— ìµœì í™”ë˜ì–´ ìˆìœ¼ë©° ì¼ë°˜ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ë£¨í”„ì— ìµœì í™”ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì˜ˆì œ ì¡°ì • í•„ìš”: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¡°ì •í•˜ì—¬ íŠ¹ì • ìš”êµ¬ì— ë§ê²Œ ë§ì¶°ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ê°•ë ¥í•œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  í‰ê°€í•˜ë©° ë°°í¬í•˜ëŠ” ê²ƒì„ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ ì£¼ì–´ ë‹¤ì–‘í•œ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ ìœ ì—°ì„±ê³¼ ë†’ì€ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

# ì„¤ì¹˜

## ê°€ìƒ í™˜ê²½ ìƒì„± (ê¶Œì¥ë¨)

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

ë¨¼ì € í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ê°€ìƒ í™˜ê²½ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ë§Œì•½ ì´ë¯¸ ì„¤ì •ëœ ê°€ìƒ í™˜ê²½ì´ ìˆë‹¤ë©´ ì´ ë‹¨ê³„ëŠ” ì„ íƒ ì‚¬í•­ì…ë‹ˆë‹¤.

- í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ ê°€ìƒ í™˜ê²½ì„ ë§Œë“­ë‹ˆë‹¤:

```bash
python -m venv env_name
```

2. í™˜ê²½ì„ í™œì„±í™”í•˜ì„¸ìš”:

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

í™˜ê²½ì´ë¦„\Scripts\activate

## ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

- Hugging Face CLI ì„¤ì¹˜í•˜ê¸°:

pip install -U "huggingface_hub[cli]"

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

2. **Hugging Face ê³„ì •ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!** (https://huggingface.co/) ê·¸ë¦¬ê³  **ì•¡ì„¸ìŠ¤ í† í°ì„ ìƒì„±**í•´ë³´ì„¸ìš”! (https://huggingface.co/settings/tokens).

3. **Hugging Face ê³„ì •ì— ë¡œê·¸ì¸**í•´ë³´ì„¸ìš”:

```bash
huggingface-cli login
```

4. **Llama-3â€“8B-Instruct** ëª¨ë¸ì˜ ì¡°ê±´ê³¼ ê°œì¸ì •ë³´ ë³´í˜¸ì •ì±…ì„ **ìˆ˜ë½**í•´ì£¼ì„¸ìš”! (https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct). **ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ ë¶€ì—¬ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”**. ë³´í†µ 15ë¶„ ì •ë„ ê±¸ë¦¬ì§€ë§Œ ê·¸ ì´ìƒì˜ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

5. ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ (ì›í•˜ëŠ” ê²½ë¡œ ì§€ì •):

```js
huggingface-cli download meta-llama/Meta-Llama-3-8B-Instruct --exclude "original/*" --local-dir meta-llama/Meta-Llama-3-8B-Instruct
```

## íŒ¨í‚¤ì§€ ì„¤ì¹˜

ë¨¼ì €, í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

Windows (CUDA ì§€ì›):

```js
pip install torch --index-url <https://download.pytorch.org/whl/cu121>
pip install accelerate transformers bitsandbytes
```

# êµ¬í˜„

## íŒŒì´í”„ë¼ì¸

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

**íƒ€ë¡œ ì „ë¬¸ê°€ì—ê²Œ ë¬¸ì˜í•´ ë³´ì„¸ìš”!**

í”¼í”Œë¼ì¸ ë°©ë²•ì€ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ë¡œ ë¡œë“œí•˜ê³  ì¶”ë¡ ì„ ìœ„í•´ ì„¤ì •í•©ë‹ˆë‹¤.

- model_id: ëª¨ë¸ ê²½ë¡œ
- torch_dtype: ê°€ì¤‘ì¹˜ì˜ ë°ì´í„° ìœ í˜•ì„ ì§€ì •í•©ë‹ˆë‹¤.

ì˜µì…˜ 1: ì–‘ìí™” ì‚¬ìš© (~8 GB)

ì–‘ìí™”ëŠ” í•˜ë“œì›¨ì–´ ìš”êµ¬ ì‚¬í•­ì„ ì¤„ì´ëŠ” ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì€ ì •ë°€ë„ë¡œ ë¡œë“œí•©ë‹ˆë‹¤. 16ë¹„íŠ¸(float16) ëŒ€ì‹ ì— 4ë¹„íŠ¸ë¡œ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëŒ€í­ ì¤„ì—¬ ì•½ 20GBì—ì„œ ì•½ 8GBë¡œ ì¤„ì…ë‹ˆë‹¤. ğŸŒŸ

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

self.pipeline = transformers.pipeline(
"text-generation",
model=self.model_id,
model_kwargs={
"torch_dtype": torch.float16,
"quantization_config": {"load_in_4bit": True},
"low_cpu_mem_usage": True,
},
)

Option 2: Without Quantization (~20 GB)

self.pipeline = transformers.pipeline(
"text-generation",
model=self.model_id,
model_kwargs={"torch_dtype": torch.float16},
)

## ì¢…ê²°ìë“¤

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

í…Œë¥´ë¯¸ë„¤ì´í„°ëŠ” ìƒì„±ëœ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ì˜ ëì„ ì‹ í˜¸í•©ë‹ˆë‹¤. ì´ë“¤ì€ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ ìƒì„±ì„ ë©ˆì¶”ì–´ì•¼ í•˜ëŠ” ì‹œì ì„ ì•Œ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. ì½”ë“œì—ì„œ img íƒœê·¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•˜ë©´:

```js
self.terminators = [self.pipeline.tokenizer.eos_token_id, self.pipeline.tokenizer.convert_tokens_to_ids("")];
```

## ë‹µë³€

LLMì€ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì…ë ¥ìœ¼ë¡œë°›ìŠµë‹ˆë‹¤. ì´ ëŒ€í™”ì—ëŠ” ì •ì˜ëœ ì—­í• ì„ ê°€ì§„ ë©”ì‹œì§€ ê¸°ë¡ì´ í¬í•¨ë©ë‹ˆë‹¤:

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

## ì „ì²´ êµ¬í˜„ ì½”ë“œ

```python
import torch
import transformers

class Llama3:
    def __init__(self, model_path):
        self.model_id = model_path
        self.pipeline = transformers.pipeline(
            "text-generation",
            model=self.model_id,
            model_kwargs={
                "torch_dtype": torch.float16,
                "quantization_config": {"load_in_4bit": True},
                "low_cpu_mem_usage": True,
            },
        )
        self.terminators = [
            self.pipeline.tokenizer.eos_token_id,
            self.pipeline.tokenizer.convert_tokens_to_ids(""),
        ]

    def get_response(
          self, query, message_history=[], max_tokens=4096, temperature=0.6, top_p=0.9
      ):
        user_prompt = message_history + [{"role": "user", "content": query}]
        prompt = self.pipeline.tokenizer.apply_chat_template(
            user_prompt, tokenize=False, add_generation_prompt=True
        )
        outputs = self.pipeline(
            prompt,
            max_new_tokens=max_tokens,
            eos_token_id=self.terminators,
            do_sample=True,
            temperature=temperature,
            top_p=top_p,
        )
        response = outputs[0]["generated_text"][len(prompt):]
        return response, user_prompt + [{"role": "assistant", "content": response}]

    def chatbot(self, system_instructions=""):
        conversation = [{"role": "system", "content": system_instructions}]
        while True:
            user_input = input("User: ")
            if user_input.lower() in ["exit", "quit"]:
                print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            response, conversation = self.get_response(user_input, conversation)
            print(f"Assistant: {response}")

if __name__ == "__main__":
    bot = Llama3("ì—¬ê¸°ì— ëª¨ë¸ ê²½ë¡œ ì…ë ¥")
    bot.chatbot()
```

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

# ê²°ë¡ 

ì´ ê¸€ì—ì„œëŠ” Llama 3ì™€ Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì±—ë´‡ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ êµ¬í˜„ì€ ì—¬ëŸ¬ë¶„ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ê²¬ê³ í•œ ì„¤ì •ì„ ìœ„í•´, ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ê°•ì œ ì¢…ë£Œë  ë•Œë§ˆë‹¤ ë‹¤ì‹œ ì‹œì‘í•˜ëŠ” ê²ƒì„ í”¼í•˜ê¸° ìœ„í•´ Flaskë‚˜ FastAPIë¥¼ ì‚¬ìš©í•˜ëŠ” ì„œë²„ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ ë³´ì„¸ìš”.

ë°±ì—”ë“œ ì„œë²„ì™€ Streamlit UIë¥¼ ì‚¬ìš©í•œ ChatGPTì™€ ìœ ì‚¬í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“œëŠ” ì™„ë²½í•œ íŠœí† ë¦¬ì–¼ì„ ê¸°ëŒ€í•´ ì£¼ì„¸ìš”!

# ì°¸ê³ ë¬¸í—Œ

<!-- cozy-coder - ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1107185301"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

ì•ˆë…•í•˜ì„¸ìš”! ì—¬ê¸° íƒ€ë¡œ ì „ë¬¸ê°€ ì…ë‹ˆë‹¤.

- [ë©”íƒ€-ë¼ë§ˆ-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
- [ë¼ë§ˆ3 ë¸”ë¡œê·¸](https://huggingface.co/blog/llama3)
- [ë©”íƒ€ ë¼ë§ˆ 3 ë¸”ë¡œê·¸](https://ai.meta.com/blog/meta-llama-3/)
- [ë¼ë§ˆ3 ê¹ƒí—ˆë¸Œ](https://github.com/meta-llama/llama3)

ì´ëŸ° ë§í¬ë“¤ì´ ìˆë‹µë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì„ ë³´ê³  ì‹¶ìœ¼ì‹œë©´ í´ë¦­í•´ë³´ì„¸ìš”! ì¦ê±°ìš´ íƒ€ë¡œì„¸ìƒ ì—¬í–‰ë˜ì„¸ìš”! ğŸŒŸ
